{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"poker-bot-dqn-leduc-notebook.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNawkpEcHN6jzXtynffAhw/"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"aRJsfnUrmS_H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606045534726,"user_tz":-60,"elapsed":7045,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"d0ff0709-e8d2-49cc-9bef-24e9f409d0f3"},"source":["!pip install git+https://github.com/datamllab/rlcard"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/datamllab/rlcard\n","  Cloning https://github.com/datamllab/rlcard to /tmp/pip-req-build-7070tsod\n","  Running command git clone -q https://github.com/datamllab/rlcard /tmp/pip-req-build-7070tsod\n","Requirement already satisfied (use --upgrade to upgrade): rlcard==0.2.6 from git+https://github.com/datamllab/rlcard in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (1.18.5)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (3.2.2)\n","Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (7.0.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (1.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (20.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (0.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->rlcard==0.2.6) (1.15.0)\n","Building wheels for collected packages: rlcard\n","  Building wheel for rlcard (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rlcard: filename=rlcard-0.2.6-cp36-none-any.whl size=6785384 sha256=b291c2ea661eabeb545c6b296b62b4bac143a4cf5366dad35651927d351fcf87\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7wx_9wrd/wheels/b3/e1/32/6535ad7ff9142e4c031af97e237e4df3e4ab14e86194738ac4\n","Successfully built rlcard\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V9-pPwFQmjxb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606045536351,"user_tz":-60,"elapsed":8654,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"1b75a9fc-4e10-4aa1-83cf-afb27fd9deb9"},"source":["%tensorflow_version 1.x # for using tensorflow.contrib\n","import tensorflow as tf"],"execution_count":2,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # for using tensorflow.contrib`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_DjHYr9NmBE8","executionInfo":{"status":"ok","timestamp":1606045536357,"user_tz":-60,"elapsed":8651,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["from collections import namedtuple\n","import random\n","import numpy as np\n","\n","Transition = namedtuple('Transition', ['state', 'action', 'reward', 'next_state', 'done'])\n","\n","class ReplayMemory(object):\n","    ''' \n","    Replay memory for saving transitions\n","    '''\n","    def __init__(self, capacity, batch_size):\n","        ''' \n","        Initialize ReplayMemory\n","\n","        :param int capacity: the size of the memory buffer\n","        :param int batch_size: the size of the batches\n","        '''\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    def push(self, *args):\n","        '''\n","        Save a transition into memory\n","        '''\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        '''\n","        Choose random sample from the memory with size of the batch size\n","        '''\n","        samples = random.sample(self.memory, batch_size)\n","        return map(np.array, zip(*samples))\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJOP-_FYlz_X","executionInfo":{"status":"ok","timestamp":1606045537047,"user_tz":-60,"elapsed":9334,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","class DQN_network(object):\n","    '''\n","    Deep Q-Network\n","    '''\n","\n","    def __init__(self, state_no=36, act_no=4, hidden_layers=[64, 32], learning_rate=0.001, device=None):\n","        ''' \n","        Initilalize the DQN_network object.\n","\n","        :param act_no (int): Number of actions (4 in Leduc Hold'em)\n","        :param state_no (list): Size of the state space (36 in Leduc Hold'em)\n","        :param hidden_layers (list): Dimension of the hidden layers\n","        :param device (torch.device): Usage CPU or GPU\n","        '''\n","        self.state_no = state_no\n","        self.act_no = act_no\n","        self.hidden_layers = hidden_layers\n","        self.learning_rate=learning_rate\n","        self.device = device\n","\n","        # DQN network based on the layers\n","        layers = self.state_no + self.hidden_layers\n","        DQN_network = [nn.Flatten()]\n","        DQN_network.append(nn.BatchNorm1d(layers[0]))\n","        for i in range(len(layers)-1):\n","            DQN_network.append(nn.Linear(layers[i], layers[i+1], bias=True))\n","            DQN_network.append(nn.Tanh())\n","        DQN_network.append(nn.Linear(layers[-1], self.act_no, bias=True))\n","        DQN_network = nn.Sequential(*DQN_network)\n","\n","        DQN_network = DQN_network.to(self.device)\n","        self.DQN_network = DQN_network\n","        self.DQN_network.eval()\n","\n","        # Initialize weights in the network\n","        for p in self.DQN_network.parameters():\n","            if len(p.data.shape) > 1:\n","                nn.init.xavier_uniform_(p.data)\n","\n","        # Define loss function\n","        self.loss_function = nn.MSELoss(reduction='mean')\n","\n","        # Define optimizer\n","        #self.optimizer =  torch.optim.Adam(self.DQN_network.parameters(), lr=self.learning_rate)\n","        self.optimizer = torch.optim.RMSprop(self.DQN_network.parameters())\n","\n","\n","    def get_qvalue(self, next_state_batch):\n","        ''' \n","        Get Q-values for the batch of the next states.\n","        It does not use gradient calculation.\n","\n","        :param np.ndarray next_state_batch: Batch of the next states\n","        :return np.ndarray Q_values: The estimated Q-values\n","        '''\n","        # Disable gradient calculation\n","        with torch.no_grad():\n","            # Create torch tensor\n","            next_state_batch = torch.from_numpy(next_state_batch).float().to(self.device)\n","            # Get Q values\n","            Q_values = self.DQN_network(next_state_batch).cpu().numpy()\n","        return Q_values\n","\n","    def update(self, state_batch, action_batch, target_batch):\n","        ''' \n","        Update the policy network\n","\n","        :param np.ndarray state_batch: Batch of states from replay memory\n","        :param np.ndarray action_batch: Batch of actions from replay memory\n","        :param np.ndarray target_batch: Batch of Q-values from the target policy, it used during the optimization step\n","        :return float batch_loss: The calculated loss on the batch       \n","        '''\n","        # Set the gradients to zero\n","        self.optimizer.zero_grad()\n","\n","        # Set the network in training mode\n","        self.DQN_network.train()\n","\n","        # Create torch tensors\n","        state_batch = torch.from_numpy(state_batch).float().to(self.device)\n","        action_batch = torch.from_numpy(action_batch).long().to(self.device)\n","        target_batch = torch.from_numpy(target_batch).float().to(self.device)\n","\n","        # Gather Q-values from network and replay memory actions\n","        Q_values = torch.gather(self.DQN_network(state_batch), dim=-1, index=action_batch.unsqueeze(-1)).squeeze(-1)\n","\n","        # Optimization step\n","        batch_loss = self.loss_function(Q_values, target_batch)\n","        batch_loss.backward()\n","        self.optimizer.step()\n","        batch_loss = batch_loss.item()\n","        self.DQN_network.eval()\n","        return batch_loss\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCR4YvyTl8Ga","executionInfo":{"status":"ok","timestamp":1606045537048,"user_tz":-60,"elapsed":9329,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from copy import deepcopy\n","import random\n","\n","class DQN_agent(object):\n","    '''\n","    DQN agent\n","    '''\n","    def __init__(self,\n","                state_no,\n","                act_no,\n","                extra_action_version=0,\n","                replay_memory_capacity=20000,\n","                replay_memory_min_sample=1000,\n","                batch_size=32,\n","                training_period=1,\n","                discount_factor=0.99,\n","                hidden_layers=[64, 32],\n","                learning_rate=0.0001,\n","                epsilon_decay_steps=20000,\n","                update_target_dqn_period=1000, \n","                device=None):\n","\n","        '''\n","        Initialize the DQN agent\n","\n","        :param int state_no: Number of states\n","        :param int act_no: Number of actions\n","        :param int extra_action_version: Mode of choosing action during evaluation phase. Action with maximum value: 0, Raise action instead of Call if possible: 1, Raise action instead of Check if possible: 2, Raise action instead of Fold if possible: 3\n","        :param int replay_memory_capacity: Replay memory size\n","        :param int replay_memory_min_sample: Minimum number of samples in the replay memory during sampling\n","        :param int batch_size: Size of batches to sample from the replay memory\n","        :param int training_period: Train the network in every N steps\n","        :param float discount_factor: Discount factor (gamma) during training the agent\n","        :param list[int] hidden_layers: Dimensions of the hidden layers in the DQN network\n","        :param float learning_rate: The learning rate in the DQN network\n","        :param int epsilon_decay_steps: Number of steps to decay epsilon\n","        :param int update_target_dqn_period: Update target network in every N steps\n","        :param torch.device device: Usage CPU or GPU\n","        '''\n","        \n","        self.replay_memory_min_sample = replay_memory_min_sample\n","        self.update_target_dqn_period = update_target_dqn_period\n","        self.discount_factor = discount_factor\n","        self.epsilon_decay_steps = epsilon_decay_steps\n","        self.batch_size = batch_size\n","        self.act_no = act_no\n","        self.training_period = training_period\n","        self.extra_action_version = extra_action_version\n","\n","        # Torch device on which a torch.Tensor will be allocated\n","        if device is None:\n","            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        else:\n","            self.device = device\n","\n","        # Create the replay memory\n","        self.memory = ReplayMemory(replay_memory_capacity, batch_size)\n","\n","        # Initialize current timestep and current training timestep\n","        self.current_timestep, self.current_training_timestep = 0, 0\n","\n","        # Create array for the epsilon values during the epsilon decay \n","        self.epsilons = np.linspace(1.0, 0.1, epsilon_decay_steps)\n","\n","        # Create the policy and the target network\n","        self.policy_dqn = DQN_network(act_no=act_no, learning_rate=learning_rate, state_no=state_no, hidden_layers=hidden_layers, device=self.device)\n","        self.target_dqn = DQN_network(act_no=act_no, learning_rate=learning_rate, state_no=state_no, hidden_layers=hidden_layers, device=self.device)\n","\n","        # Set use_raw value for the RLCard environment\n","        self.use_raw = False\n","\n","    def store_and_train(self, transition):\n","        ''' \n","        Save transition into memory and train the agent based on the training period.\n","\n","        :param tuple transition: The transition tuple 'state', 'action', 'reward', 'next_state', 'done'\n","        \n","        '''\n","        (state, action, reward, next_state, done) = tuple(transition)\n","\n","        # Store transition in replay memory\n","        self.memory.push(state['obs'], action, reward, next_state['obs'], done)\n","        # Increment the number of timesteps\n","        self.current_timestep += 1\n","        # Train the agent if the replay memory has data already and agent reached the next training period\n","        time_between = self.current_timestep - self.replay_memory_min_sample\n","        if time_between>=0 and time_between%self.training_period == 0:\n","            self.train()\n","\n","    def discard_invalid_actions(self, action_probs, valid_actions):\n","        ''' \n","        Remove invalid actions and normalize the probabilities.\n","\n","        :param numpy.array[float] action_probs: Probabilities of all action\n","        :param list[int] valid_actions: Valid actions in the current state\n","        :return numpy.array[float] norm_valid_action_probs: Probabilities of valid actions\n","        '''\n","        # Initialize new array\n","        norm_valid_action_probs = np.zeros(action_probs.shape[0])\n","        # Add probability values of valid actions to the array\n","        norm_valid_action_probs[valid_actions] = action_probs[valid_actions]\n","        # Normalize probabilities\n","        norm_valid_action_probs[valid_actions] = 1 / len(valid_actions)\n","        return norm_valid_action_probs\n","\n","    def predict(self, state):\n","        ''' \n","        Predict the action probabilities.\n","\n","        :param numpy.array[float] state: Current state\n","        :return numpy.array[float] q_values: Array of Q values  \n","        '''\n","        epsilon = self.epsilons[min(self.current_timestep, self.epsilon_decay_steps-1)]\n","        actions = np.ones(self.act_no, dtype=float) * epsilon / self.act_no\n","        q_values = self.policy_dqn.get_qvalue(np.expand_dims(state, 0))[0]\n","        best_action = np.argmax(q_values)\n","        actions[best_action] += (1.0 - epsilon)\n","        return actions\n","\n","    def step(self, state):\n","        ''' \n","        Define step function for the RLCard environment.\n","        Get the action for the current state for training purpose.\n","        If neccessary, remove invalid action pobabilities.\n","\n","        :param numpy.array state: The current state\n","        :return int action: The chosen action in the current state\n","        '''\n","        actions = self.predict(state['obs'])\n","        norm_valid_action_probs = self.discard_invalid_actions(actions, state['legal_actions'])\n","        action = np.random.choice(np.arange(len(actions)), p=norm_valid_action_probs)\n","        return action\n","\n","\n","    def eval_step(self, state):\n","        ''' \n","        Define eval_step function for the RLCard environment.\n","        Get the action for the evaluation purpose instead of training purpose.\n","\n","        :param numpy.array state: The current state\n","        :return int action: The chosen action in the current state\n","        '''\n","        q_values = self.policy_dqn.get_qvalue(np.expand_dims(state['obs'], 0))[0]\n","        norm_valid_action_probs = self.discard_invalid_actions(np.exp(q_values), state['legal_actions'])\n","        # Check version of choosing action\n","        if self.extra_action_version == 1:\n","          # If Raise (1) is a valid action and the best action is Call (0)\n","          if 1 in state['legal_actions'] and np.argmax(norm_valid_action_probs)==0:\n","            best_action = 1\n","          else:\n","            best_action = np.argmax(norm_valid_action_probs)\n","        elif self.extra_action_version == 2:\n","          # If Raise (1) is a valid action and the best action is Check (3)\n","          if 1 in state['legal_actions'] and np.argmax(norm_valid_action_probs)==3:\n","            best_action = 1\n","          else:\n","            best_action = np.argmax(norm_valid_action_probs)\n","        elif self.extra_action_version == 3:\n","          # If Raise (1) is a valid action and the best action is Fold (2)\n","          if 1 in state['legal_actions'] and np.argmax(norm_valid_action_probs)==2:\n","            best_action = 1\n","          else:\n","            best_action = np.argmax(norm_valid_action_probs)\n","        else:\n","          best_action = np.argmax(norm_valid_action_probs)\n","        return best_action, norm_valid_action_probs\n","\n","    \n","    def train(self):\n","        ''' \n","        Train the agent.\n","\n","        return float loss: The loss of the current batch\n","        '''\n","        state_batch, action_batch, reward_batch, next_state_batch, done_batch = self.memory.sample(self.batch_size)\n","\n","        # Get best next action using the policy network\n","        q_values_next = self.policy_dqn.get_qvalue(next_state_batch)\n","        best_actions = np.argmax(q_values_next, axis=1)\n","\n","        # Calculate Q values from the target policy\n","        q_values_next_target = self.target_dqn.get_qvalue(next_state_batch)\n","        target_batch = reward_batch + np.invert(done_batch).astype(np.float32) * self.discount_factor * q_values_next_target[np.arange(self.batch_size), best_actions]\n","\n","        # Update policy network\n","        state_batch = np.array(state_batch)\n","        loss = self.policy_dqn.update(state_batch, action_batch, target_batch)\n","\n","        # Update target network based on the target update period\n","        if self.current_training_timestep % self.update_target_dqn_period == 0:\n","            self.target_dqn = deepcopy(self.policy_dqn)\n","\n","        self.current_training_timestep += 1\n","\n","\n","    def get_state_dict(self):\n","        ''' \n","        Get the state dictionaries.\n","\n","        :return dict model_dict: Dictionaries containing the whole state of the policy and target modules\n","        '''\n","        model_dict = {'policy_network': self.policy_dqn.DQN_network.state_dict(), 'target_network': self.target_dqn.DQN_network.state_dict()}\n","        return model_dict\n","\n","    def load_networks(self, checkpoint):\n","        ''' \n","        Load network models.\n","\n","        :param dict checkpoint: Checkpoint of the policy and target networks\n","        '''\n","        self.policy_dqn.DQN_network.load_state_dict(checkpoint['policy_network'])\n","        self.target_dqn.DQN_network.load_state_dict(checkpoint['target_network'])\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YajsvaIsw2W4","executionInfo":{"status":"ok","timestamp":1606045647935,"user_tz":-60,"elapsed":514,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["import os\n","import csv\n","import matplotlib.pyplot as plt\n","\n","def plot(logdir, title):\n","    ''' \n","    Read data from csv file and plot the results\n","\n","    :param string logdir: Logging directory\n","    :param string title: Title of the plot\n","    '''\n","    csv_path = os.path.join(log_dir, 'performance.csv')\n","    save_path = log_dir\n","\n","    with open(csv_path) as csvfile:\n","        print(csv_path)\n","        reader = csv.DictReader(csvfile)\n","        xs = [0]\n","        ys = [0]\n","        for row in reader:\n","            xs.append(int(row['timestep']))\n","            ys.append(float(row['reward']))\n","        plt.plot(xs, ys)\n","        plt.xlabel('timestep')\n","        plt.ylabel('reward')\n","        plt.title(title)\n","        plt.legend(['DQN'])\n","        plt.ylim(min(-0.5, min(ys)), max(ys)+0.5)\n","        plt.grid()\n","        plt.savefig(save_path)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZK0dotrUla77","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606045551969,"user_tz":-60,"elapsed":24235,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"ec6060ff-7c97-422f-d070-07508075f0c2"},"source":["import rlcard\n","from rlcard import models\n","from rlcard.agents import RandomAgent\n","from rlcard.utils import seeding, tournament\n","from rlcard.utils import Logger\n","import torch\n","import os\n","\n","# Create environments\n","env = rlcard.make('leduc-holdem', config={'seed': 0})\n","eval_env = rlcard.make('leduc-holdem', config={'seed': 0})\n","\n","# Set a global seed\n","seeding.create_seed(0)\n","\n","# Play agressive game based on the version of choosing actual action\n","# Action with maximum value: 0\n","# Raise action instead of Call if possible: 1\n","# Raise action instead of Check if possible: 2\n","# Raise action instead of Fold if possible: 3\n","extra_action_version=1\n","\n","# Opponent agent\n","# Random agent: 0\n","# Pretrained agent with nfsp: 1\n","opponent_agent_version_train=1\n","opponent_agent_version_eval=0\n","\n","# The paths for saving the logs and learning curves\n","log_dir = './experiments/leduc_holdem_dqn_result/'\n","\n","# Create DQN agent\n","agent = DQN_agent(state_no=env.state_shape,\n","                  act_no=env.action_num, \n","                  replay_memory_min_sample=1000,\n","                  training_period=10,\n","                  hidden_layers=[128, 128],\n","                  device=torch.device('cpu'),\n","                  extra_action_version=extra_action_version)\n","\n","# Create opponent agent for training\n","if opponent_agent_version_train == 1:\n","  # Create a pre-trained NFSP agent\n","  opponent_agent_train = models.load('leduc-holdem-nfsp').agents[0]\n","else:\n","  # Create a random agent\n","  opponent_agent_train = RandomAgent(action_num=eval_env.action_num)\n","\n","# Create opponent agent for evaluation\n","if opponent_agent_version_eval == 1:\n","  # Create a pre-trained NFSP agent\n","  opponent_agent_eval = models.load('leduc-holdem-nfsp').agents[0]\n","else:\n","  # Create a random agent\n","  opponent_agent_eval = RandomAgent(action_num=eval_env.action_num)\n","\n","# Add the agent to the environments\n","env.set_agents([agent, opponent_agent_train])\n","eval_env.set_agents([agent, opponent_agent_eval])\n","\n","# Initialize logger\n","logger = Logger(log_dir)\n","\n","# Number of episodes, number of games during evaluation and evaluation in every N steps\n","episode_no, evaluate_games, evaluate_period = 1000, 100, 10\n","\n","for episode in range(episode_no):\n","    # Generate data from the environment\n","    trajectories, _ = env.run(is_training=True)\n","\n","    # Feed transitions into agent memory, and train the agent\n","    for ts in trajectories[0]:\n","        agent.store_and_train(ts)\n","\n","    # Evaluate the performance\n","    if episode % evaluate_period == 0:\n","        logger.log_performance(env.timestep, tournament(eval_env, evaluate_games)[0])\n","\n","# Close files in the logger\n","logger.close_files()\n","\n","# Save model\n","save_dir = 'models/dqn'\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","state_dict = agent.get_state_dict()\n","torch.save(state_dict, os.path.join(save_dir, 'model.pth'))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/models/pretrained_models.py:23: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/nfsp_agent.py:114: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:256: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:267: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:280: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:242: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:242: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:242: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:244: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:247: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_global_step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/models/pretrained_models.py:40: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","INFO:tensorflow:Restoring parameters from /usr/local/lib/python3.6/dist-packages/rlcard/models/pretrained/leduc_holdem_nfsp/model\n","\n","----------------------------------------\n","  timestep     |  6\n","  reward       |  1.145\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  40\n","  reward       |  1.345\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  71\n","  reward       |  0.755\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  102\n","  reward       |  1.17\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  137\n","  reward       |  1.155\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  169\n","  reward       |  1.21\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  207\n","  reward       |  1.27\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  240\n","  reward       |  1.44\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  268\n","  reward       |  1.15\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  304\n","  reward       |  1.06\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  333\n","  reward       |  1.055\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  373\n","  reward       |  1.02\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  404\n","  reward       |  1.035\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  433\n","  reward       |  1.27\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  472\n","  reward       |  0.71\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  512\n","  reward       |  1.35\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  546\n","  reward       |  0.995\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  581\n","  reward       |  0.97\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  621\n","  reward       |  1.065\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  657\n","  reward       |  1.05\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  689\n","  reward       |  1.075\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  726\n","  reward       |  1.655\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  754\n","  reward       |  1.2\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  793\n","  reward       |  1.97\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  827\n","  reward       |  1.62\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  874\n","  reward       |  0.91\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  900\n","  reward       |  0.83\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  944\n","  reward       |  0.905\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  981\n","  reward       |  1.075\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1011\n","  reward       |  1.025\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1041\n","  reward       |  0.81\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1070\n","  reward       |  0.72\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1111\n","  reward       |  0.945\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1147\n","  reward       |  1.015\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1187\n","  reward       |  1.545\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1222\n","  reward       |  1.64\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1255\n","  reward       |  1.355\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1292\n","  reward       |  1.24\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1323\n","  reward       |  1.15\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1346\n","  reward       |  2.03\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1377\n","  reward       |  1.23\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1410\n","  reward       |  1.105\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1438\n","  reward       |  0.765\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1475\n","  reward       |  1.5\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1511\n","  reward       |  1.025\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1551\n","  reward       |  0.9\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1589\n","  reward       |  1.125\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1621\n","  reward       |  1.12\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1654\n","  reward       |  1.54\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1684\n","  reward       |  0.9\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1715\n","  reward       |  1.1\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1746\n","  reward       |  0.82\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1777\n","  reward       |  1.61\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1812\n","  reward       |  1.38\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1852\n","  reward       |  1.05\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1886\n","  reward       |  1.01\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1926\n","  reward       |  1.105\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1955\n","  reward       |  1.475\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1989\n","  reward       |  1.04\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2030\n","  reward       |  0.985\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2068\n","  reward       |  1.305\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2104\n","  reward       |  1.33\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2145\n","  reward       |  1.44\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2183\n","  reward       |  1.09\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2214\n","  reward       |  0.955\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2253\n","  reward       |  1.165\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2283\n","  reward       |  0.85\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2317\n","  reward       |  0.99\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2355\n","  reward       |  1.165\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2385\n","  reward       |  1.71\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2420\n","  reward       |  0.75\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2449\n","  reward       |  0.865\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2484\n","  reward       |  1.245\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2518\n","  reward       |  0.68\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2558\n","  reward       |  0.76\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2585\n","  reward       |  1.195\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2620\n","  reward       |  1.085\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2659\n","  reward       |  1.185\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2702\n","  reward       |  0.475\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2741\n","  reward       |  0.89\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2775\n","  reward       |  1.945\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2803\n","  reward       |  1.325\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2834\n","  reward       |  1.905\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2865\n","  reward       |  1.42\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2899\n","  reward       |  1.135\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2934\n","  reward       |  1.135\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2970\n","  reward       |  0.955\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3005\n","  reward       |  0.915\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3036\n","  reward       |  1.38\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3075\n","  reward       |  1.355\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3104\n","  reward       |  1.555\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3130\n","  reward       |  1.035\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3167\n","  reward       |  1.015\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3203\n","  reward       |  1.59\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3242\n","  reward       |  1.18\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3288\n","  reward       |  0.94\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3318\n","  reward       |  0.425\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3359\n","  reward       |  0.89\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3391\n","  reward       |  1.51\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3418\n","  reward       |  1.5\n","----------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UcTuXaqCnq5B","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"ok","timestamp":1606045654661,"user_tz":-60,"elapsed":863,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"9ba531f7-0618-495a-ed4e-fd04afe545bc"},"source":["# Plot the learning curve\n","title = 'Leduc Holdem DQN action version: ' + str(extra_action_version) + ', agent training: ' + str(opponent_agent_version_train) + ', agent eval: ' + str(opponent_agent_version_eval)\n","plot(log_dir, title)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["./experiments/leduc_holdem_dqn_result/performance.csv\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}