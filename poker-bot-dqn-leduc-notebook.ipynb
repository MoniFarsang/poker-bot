{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"poker-bot-dqn-leduc-notebook.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRJsfnUrmS_H","executionInfo":{"status":"ok","timestamp":1606161375878,"user_tz":-60,"elapsed":10572,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"70b21539-a165-43a2-ffbf-6123f0e843d4"},"source":["!pip install git+https://github.com/datamllab/rlcard"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/datamllab/rlcard\n","  Cloning https://github.com/datamllab/rlcard to /tmp/pip-req-build-i7ey2gkv\n","  Running command git clone -q https://github.com/datamllab/rlcard /tmp/pip-req-build-i7ey2gkv\n","Requirement already satisfied (use --upgrade to upgrade): rlcard==0.2.6 from git+https://github.com/datamllab/rlcard in /usr/local/lib/python3.6/dist-packages\n","Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (1.18.5)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (3.2.2)\n","Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (7.0.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (1.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (20.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->rlcard==0.2.6) (1.15.0)\n","Building wheels for collected packages: rlcard\n","  Building wheel for rlcard (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rlcard: filename=rlcard-0.2.6-cp36-none-any.whl size=6785384 sha256=101895c30b4f4777de01d30c37482017e5c5199edd30681e355c3f7523859285\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-scmn22sv/wheels/b3/e1/32/6535ad7ff9142e4c031af97e237e4df3e4ab14e86194738ac4\n","Successfully built rlcard\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9-pPwFQmjxb","executionInfo":{"status":"ok","timestamp":1606161377470,"user_tz":-60,"elapsed":12138,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"35a426bb-4e4f-4b6e-c982-480b5e328e52"},"source":["%tensorflow_version 1.x # for using tensorflow.contrib\n","import tensorflow as tf"],"execution_count":2,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # for using tensorflow.contrib`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_DjHYr9NmBE8","executionInfo":{"status":"ok","timestamp":1606161377472,"user_tz":-60,"elapsed":12130,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["from collections import namedtuple\n","import random\n","import numpy as np\n","\n","Transition = namedtuple('Transition', ['state', 'action', 'reward', 'next_state', 'done'])\n","\n","class ReplayMemory(object):\n","    ''' \n","    Replay memory for saving transitions\n","    '''\n","    def __init__(self, capacity, batch_size):\n","        ''' \n","        Initialize ReplayMemory\n","\n","        :param int capacity: the size of the memory buffer\n","        :param int batch_size: the size of the batches\n","        '''\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    def push(self, *args):\n","        '''\n","        Save a transition into memory\n","        '''\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        '''\n","        Choose random sample from the memory with size of the batch size\n","        '''\n","        samples = random.sample(self.memory, batch_size)\n","        return map(np.array, zip(*samples))\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJOP-_FYlz_X","executionInfo":{"status":"ok","timestamp":1606161378315,"user_tz":-60,"elapsed":12966,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","class DQN_network(object):\n","    '''\n","    Deep Q-Network\n","    '''\n","\n","    def __init__(self, state_no=36, act_no=4, hidden_layers=[64, 32], learning_rate=0.001, device=None):\n","        ''' \n","        Initilalize the DQN_network object.\n","\n","        :param act_no (int): Number of actions (4 in Leduc Hold'em)\n","        :param state_no (list): Size of the state space (36 in Leduc Hold'em)\n","        :param hidden_layers (list): Dimension of the hidden layers\n","        :param device (torch.device): Usage CPU or GPU\n","        '''\n","        self.state_no = state_no\n","        self.act_no = act_no\n","        self.hidden_layers = hidden_layers\n","        self.learning_rate=learning_rate\n","        self.device = device\n","\n","        # DQN network based on the layers\n","        layers = self.state_no + self.hidden_layers\n","        DQN_network = [nn.Flatten()]\n","        DQN_network.append(nn.BatchNorm1d(layers[0]))\n","        for i in range(len(layers)-1):\n","            DQN_network.append(nn.Linear(layers[i], layers[i+1], bias=True))\n","            DQN_network.append(nn.Tanh())\n","        DQN_network.append(nn.Linear(layers[-1], self.act_no, bias=True))\n","        DQN_network = nn.Sequential(*DQN_network)\n","\n","        DQN_network = DQN_network.to(self.device)\n","        self.DQN_network = DQN_network\n","        self.DQN_network.eval()\n","\n","        # Initialize weights in the network\n","        for p in self.DQN_network.parameters():\n","            if len(p.data.shape) > 1:\n","                nn.init.xavier_uniform_(p.data)\n","\n","        # Define loss function\n","        self.loss_function = nn.MSELoss(reduction='mean')\n","\n","        # Define optimizer\n","        #self.optimizer =  torch.optim.Adam(self.DQN_network.parameters(), lr=self.learning_rate)\n","        self.optimizer = torch.optim.RMSprop(self.DQN_network.parameters())\n","\n","\n","    def get_qvalue(self, next_state_batch):\n","        ''' \n","        Get Q-values for the batch of the next states.\n","        It does not use gradient calculation.\n","\n","        :param np.ndarray next_state_batch: Batch of the next states\n","        :return np.ndarray Q_values: The estimated Q-values\n","        '''\n","        # Disable gradient calculation\n","        with torch.no_grad():\n","            # Create torch tensor\n","            next_state_batch = torch.from_numpy(next_state_batch).float().to(self.device)\n","            # Get Q values\n","            Q_values = self.DQN_network(next_state_batch).cpu().numpy()\n","        return Q_values\n","\n","    def update(self, state_batch, action_batch, target_batch):\n","        ''' \n","        Update the policy network\n","\n","        :param np.ndarray state_batch: Batch of states from replay memory\n","        :param np.ndarray action_batch: Batch of actions from replay memory\n","        :param np.ndarray target_batch: Batch of Q-values from the target policy, it used during the optimization step\n","        :return float batch_loss: The calculated loss on the batch       \n","        '''\n","        # Set the gradients to zero\n","        self.optimizer.zero_grad()\n","\n","        # Set the network in training mode\n","        self.DQN_network.train()\n","\n","        # Create torch tensors\n","        state_batch = torch.from_numpy(state_batch).float().to(self.device)\n","        action_batch = torch.from_numpy(action_batch).long().to(self.device)\n","        target_batch = torch.from_numpy(target_batch).float().to(self.device)\n","\n","        # Gather Q-values from network and replay memory actions\n","        Q_values = torch.gather(self.DQN_network(state_batch), dim=-1, index=action_batch.unsqueeze(-1)).squeeze(-1)\n","\n","        # Optimization step\n","        batch_loss = self.loss_function(Q_values, target_batch)\n","        batch_loss.backward()\n","        self.optimizer.step()\n","        batch_loss = batch_loss.item()\n","        self.DQN_network.eval()\n","        return batch_loss\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCR4YvyTl8Ga","executionInfo":{"status":"ok","timestamp":1606161378316,"user_tz":-60,"elapsed":12961,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from copy import deepcopy\n","import random\n","\n","class DQN_agent(object):\n","    '''\n","    DQN agent\n","    '''\n","    def __init__(self,\n","                state_no,\n","                act_no,\n","                extra_action_version=0,\n","                replay_memory_capacity=20000,\n","                replay_memory_min_sample=1000,\n","                batch_size=32,\n","                training_period=1,\n","                discount_factor=0.99,\n","                hidden_layers=[64, 32],\n","                learning_rate=0.0001,\n","                epsilon_decay_steps=20000,\n","                update_target_dqn_period=1000, \n","                device=None):\n","\n","        '''\n","        Initialize the DQN agent\n","\n","        :param int state_no: Number of states\n","        :param int act_no: Number of actions\n","        :param int extra_action_version: Mode of choosing action during evaluation phase. Action with maximum value: 0, Raise action instead of Call if possible: 1, Raise action instead of Check if possible: 2, Raise action instead of Fold if possible: 3\n","        :param int replay_memory_capacity: Replay memory size\n","        :param int replay_memory_min_sample: Minimum number of samples in the replay memory during sampling\n","        :param int batch_size: Size of batches to sample from the replay memory\n","        :param int training_period: Train the network in every N steps\n","        :param float discount_factor: Discount factor (gamma) during training the agent\n","        :param list[int] hidden_layers: Dimensions of the hidden layers in the DQN network\n","        :param float learning_rate: The learning rate in the DQN network\n","        :param int epsilon_decay_steps: Number of steps to decay epsilon\n","        :param int update_target_dqn_period: Update target network in every N steps\n","        :param torch.device device: Usage CPU or GPU\n","        '''\n","        \n","        self.replay_memory_min_sample = replay_memory_min_sample\n","        self.update_target_dqn_period = update_target_dqn_period\n","        self.discount_factor = discount_factor\n","        self.epsilon_decay_steps = epsilon_decay_steps\n","        self.batch_size = batch_size\n","        self.act_no = act_no\n","        self.training_period = training_period\n","        self.extra_action_version = extra_action_version\n","\n","        # Torch device on which a torch.Tensor will be allocated\n","        if device is None:\n","            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        else:\n","            self.device = device\n","\n","        # Create the replay memory\n","        self.memory = ReplayMemory(replay_memory_capacity, batch_size)\n","\n","        # Initialize current timestep and current training timestep\n","        self.current_timestep, self.current_training_timestep = 0, 0\n","\n","        # Create array for the epsilon values during the epsilon decay \n","        self.epsilons = np.linspace(1.0, 0.1, epsilon_decay_steps)\n","\n","        # Create the policy and the target network\n","        self.policy_dqn = DQN_network(act_no=act_no, learning_rate=learning_rate, state_no=state_no, hidden_layers=hidden_layers, device=self.device)\n","        self.target_dqn = DQN_network(act_no=act_no, learning_rate=learning_rate, state_no=state_no, hidden_layers=hidden_layers, device=self.device)\n","\n","        # Set use_raw value for the RLCard environment\n","        self.use_raw = False\n","\n","    def store_and_train(self, transition):\n","        ''' \n","        Save transition into memory and train the agent based on the training period.\n","\n","        :param tuple transition: The transition tuple 'state', 'action', 'reward', 'next_state', 'done'\n","        \n","        '''\n","        (state, action, reward, next_state, done) = tuple(transition)\n","\n","        # Store transition in replay memory\n","        self.memory.push(state['obs'], action, reward, next_state['obs'], done)\n","        # Increment the number of timesteps\n","        self.current_timestep += 1\n","        # Train the agent if the replay memory has data already and agent reached the next training period\n","        time_between = self.current_timestep - self.replay_memory_min_sample\n","        if time_between>=0 and time_between%self.training_period == 0:\n","            self.train()\n","\n","    def discard_invalid_actions(self, action_probs, valid_actions):\n","        ''' \n","        Remove invalid actions and normalize the probabilities.\n","\n","        :param numpy.array[float] action_probs: Probabilities of all action\n","        :param list[int] valid_actions: Valid actions in the current state\n","        :return numpy.array[float] norm_valid_action_probs: Probabilities of valid actions\n","        '''\n","        # Initialize new array\n","        norm_valid_action_probs = np.zeros(action_probs.shape[0])\n","        # Add probability values of valid actions to the array\n","        norm_valid_action_probs[valid_actions] = action_probs[valid_actions]\n","        # Normalize probabilities\n","        norm_valid_action_probs[valid_actions] = 1 / len(valid_actions)\n","        return norm_valid_action_probs\n","\n","    def predict(self, state):\n","        ''' \n","        Predict the action probabilities.\n","\n","        :param numpy.array[float] state: Current state\n","        :return numpy.array[float] q_values: Array of Q values  \n","        '''\n","        epsilon = self.epsilons[min(self.current_timestep, self.epsilon_decay_steps-1)]\n","        actions = np.ones(self.act_no, dtype=float) * epsilon / self.act_no\n","        q_values = self.policy_dqn.get_qvalue(np.expand_dims(state, 0))[0]\n","        best_action = np.argmax(q_values)\n","        actions[best_action] += (1.0 - epsilon)\n","        return actions\n","\n","    def step(self, state):\n","        ''' \n","        Define step function for the RLCard environment.\n","        Get the action for the current state for training purpose.\n","        If neccessary, remove invalid action pobabilities.\n","\n","        :param numpy.array state: The current state\n","        :return int action: The chosen action in the current state\n","        '''\n","        actions = self.predict(state['obs'])\n","        norm_valid_action_probs = self.discard_invalid_actions(actions, state['legal_actions'])\n","        action = np.random.choice(np.arange(len(actions)), p=norm_valid_action_probs)\n","        return action\n","\n","\n","    def eval_step(self, state):\n","        ''' \n","        Define eval_step function for the RLCard environment.\n","        Get the action for the evaluation purpose instead of training purpose.\n","\n","        :param numpy.array state: The current state\n","        :return int action: The chosen action in the current state\n","        '''\n","        q_values = self.policy_dqn.get_qvalue(np.expand_dims(state['obs'], 0))[0]\n","        norm_valid_action_probs = self.discard_invalid_actions(np.exp(q_values), state['legal_actions'])\n","        # Check version of choosing action\n","        if self.extra_action_version == 1:\n","          # If Raise (1) is a valid action and the best action is Call (0)\n","          if 1 in state['legal_actions'] and np.argmax(norm_valid_action_probs)==0:\n","            best_action = 1\n","          else:\n","            best_action = np.argmax(norm_valid_action_probs)\n","        elif self.extra_action_version == 2:\n","          # If Raise (1) is a valid action and the best action is Check (3)\n","          if 1 in state['legal_actions'] and np.argmax(norm_valid_action_probs)==3:\n","            best_action = 1\n","          else:\n","            best_action = np.argmax(norm_valid_action_probs)\n","        elif self.extra_action_version == 3:\n","          # If Raise (1) is a valid action and the best action is Fold (2)\n","          if 1 in state['legal_actions'] and np.argmax(norm_valid_action_probs)==2:\n","            best_action = 1\n","          else:\n","            best_action = np.argmax(norm_valid_action_probs)\n","        else:\n","          best_action = np.argmax(norm_valid_action_probs)\n","        return best_action, norm_valid_action_probs\n","\n","    \n","    def train(self):\n","        ''' \n","        Train the agent.\n","\n","        return float loss: The loss of the current batch\n","        '''\n","        state_batch, action_batch, reward_batch, next_state_batch, done_batch = self.memory.sample(self.batch_size)\n","\n","        # Get best next action using the policy network\n","        q_values_next = self.policy_dqn.get_qvalue(next_state_batch)\n","        best_actions = np.argmax(q_values_next, axis=1)\n","\n","        # Calculate Q values from the target policy\n","        q_values_next_target = self.target_dqn.get_qvalue(next_state_batch)\n","        target_batch = reward_batch + np.invert(done_batch).astype(np.float32) * self.discount_factor * q_values_next_target[np.arange(self.batch_size), best_actions]\n","\n","        # Update policy network\n","        state_batch = np.array(state_batch)\n","        loss = self.policy_dqn.update(state_batch, action_batch, target_batch)\n","\n","        # Update target network based on the target update period\n","        if self.current_training_timestep % self.update_target_dqn_period == 0:\n","            self.target_dqn = deepcopy(self.policy_dqn)\n","\n","        self.current_training_timestep += 1\n","\n","\n","    def get_state_dict(self):\n","        ''' \n","        Get the state dictionaries.\n","\n","        :return dict model_dict: Dictionaries containing the whole state of the policy and target modules\n","        '''\n","        model_dict = {'policy_network': self.policy_dqn.DQN_network.state_dict(), 'target_network': self.target_dqn.DQN_network.state_dict()}\n","        return model_dict\n","\n","    def load_networks(self, checkpoint):\n","        ''' \n","        Load network models.\n","\n","        :param dict checkpoint: Checkpoint of the policy and target networks\n","        '''\n","        self.policy_dqn.DQN_network.load_state_dict(checkpoint['policy_network'])\n","        self.target_dqn.DQN_network.load_state_dict(checkpoint['target_network'])\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YajsvaIsw2W4","executionInfo":{"status":"ok","timestamp":1606161378317,"user_tz":-60,"elapsed":12954,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["import os\n","import csv\n","import matplotlib.pyplot as plt\n","\n","def plot(logdir, title):\n","    ''' \n","    Read data from csv file and plot the results\n","\n","    :param string logdir: Logging directory\n","    :param string title: Title of the plot\n","    '''\n","    csv_path = os.path.join(log_dir, 'performance.csv')\n","    save_path = log_dir\n","\n","    with open(csv_path) as csvfile:\n","        print(csv_path)\n","        reader = csv.DictReader(csvfile)\n","        xs = [0]\n","        ys = [0]\n","        for row in reader:\n","            xs.append(int(row['timestep']))\n","            ys.append(float(row['reward']))\n","        plt.plot(xs, ys)\n","        plt.xlabel('timestep')\n","        plt.ylabel('reward')\n","        plt.title(title)\n","        plt.legend(['DQN'])\n","        plt.ylim(min(-0.5, min(ys)), max(ys)+0.5)\n","        plt.grid()\n","        plt.savefig(save_path)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZK0dotrUla77","executionInfo":{"status":"ok","timestamp":1606161392276,"user_tz":-60,"elapsed":26904,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"36ea9623-81ba-4f17-c18a-683f0cb811e4"},"source":["import rlcard\n","from rlcard import models\n","from rlcard.agents import RandomAgent\n","from rlcard.utils import seeding, tournament\n","from rlcard.utils import Logger\n","import torch\n","import os\n","\n","# Create environments\n","env = rlcard.make('leduc-holdem', config={'seed': 0})\n","eval_env = rlcard.make('leduc-holdem', config={'seed': 0})\n","\n","# Set a global seed\n","seeding.create_seed(0)\n","\n","# Play agressive game based on the version of choosing actual action\n","# Action with maximum value: 0\n","# Raise action instead of Call if possible: 1\n","# Raise action instead of Check if possible: 2\n","# Raise action instead of Fold if possible: 3\n","extra_action_version=1\n","\n","# Opponent agent\n","# Random agent: 0\n","# Pretrained agent with nfsp: 1\n","opponent_agent_version_train=1\n","opponent_agent_version_eval=0\n","\n","# The paths for saving the logs and learning curves\n","log_dir = './experiments/leduc_holdem_dqn_result/'\n","\n","# Create DQN agent\n","agent = DQN_agent(state_no=env.state_shape,\n","                  act_no=env.action_num, \n","                  replay_memory_min_sample=1000,\n","                  training_period=10,\n","                  hidden_layers=[128, 128],\n","                  device=torch.device('cpu'),\n","                  extra_action_version=extra_action_version)\n","\n","# Create opponent agent for training\n","if opponent_agent_version_train == 1:\n","  # Create a pre-trained NFSP agent\n","  opponent_agent_train = models.load('leduc-holdem-nfsp').agents[0]\n","else:\n","  # Create a random agent\n","  opponent_agent_train = RandomAgent(action_num=eval_env.action_num)\n","\n","# Create opponent agent for evaluation\n","if opponent_agent_version_eval == 1:\n","  # Create a pre-trained NFSP agent\n","  opponent_agent_eval = models.load('leduc-holdem-nfsp').agents[0]\n","else:\n","  # Create a random agent\n","  opponent_agent_eval = RandomAgent(action_num=eval_env.action_num)\n","\n","# Add the agent to the environments\n","env.set_agents([agent, opponent_agent_train])\n","eval_env.set_agents([agent, opponent_agent_eval])\n","\n","# Initialize logger\n","logger = Logger(log_dir)\n","\n","# Number of episodes, number of games during evaluation and evaluation in every N steps\n","episode_no, evaluate_games, evaluate_period = 1000, 100, 10\n","\n","for episode in range(episode_no):\n","    # Generate data from the environment\n","    trajectories, _ = env.run(is_training=True)\n","\n","    # Feed transitions into agent memory, and train the agent\n","    for ts in trajectories[0]:\n","        agent.store_and_train(ts)\n","\n","    # Evaluate the performance\n","    if episode % evaluate_period == 0:\n","        logger.log_performance(env.timestep, tournament(eval_env, evaluate_games)[0])\n","\n","# Close files in the logger\n","logger.close_files()\n","\n","# Save model\n","save_dir = 'models/dqn'\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","state_dict = agent.get_state_dict()\n","torch.save(state_dict, os.path.join(save_dir, 'model.pth'))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/models/pretrained_models.py:23: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/nfsp_agent.py:114: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:256: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:267: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:280: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:242: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:242: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:242: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:244: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/agents/dqn_agent.py:247: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_global_step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/rlcard/models/pretrained_models.py:40: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","INFO:tensorflow:Restoring parameters from /usr/local/lib/python3.6/dist-packages/rlcard/models/pretrained/leduc_holdem_nfsp/model\n","\n","----------------------------------------\n","  timestep     |  6\n","  reward       |  1.38\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  34\n","  reward       |  1.075\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  77\n","  reward       |  1.27\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  113\n","  reward       |  1.46\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  141\n","  reward       |  0.875\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  178\n","  reward       |  1.205\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  215\n","  reward       |  1.2\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  243\n","  reward       |  1.95\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  271\n","  reward       |  1.02\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  302\n","  reward       |  1.27\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  333\n","  reward       |  1.21\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  364\n","  reward       |  1.18\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  406\n","  reward       |  0.975\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  438\n","  reward       |  1.18\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  467\n","  reward       |  0.82\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  506\n","  reward       |  1.795\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  533\n","  reward       |  1.005\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  551\n","  reward       |  1.22\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  586\n","  reward       |  1.475\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  624\n","  reward       |  1.195\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  653\n","  reward       |  0.495\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  693\n","  reward       |  1.015\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  740\n","  reward       |  1.28\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  778\n","  reward       |  1.34\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  810\n","  reward       |  1.045\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  852\n","  reward       |  0.86\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  883\n","  reward       |  1.325\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  915\n","  reward       |  0.735\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  955\n","  reward       |  1.24\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  988\n","  reward       |  0.82\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1023\n","  reward       |  0.915\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1052\n","  reward       |  1.02\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1076\n","  reward       |  1.235\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1115\n","  reward       |  1.215\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1144\n","  reward       |  0.835\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1173\n","  reward       |  1.155\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1205\n","  reward       |  1.23\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1247\n","  reward       |  1.225\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1279\n","  reward       |  0.59\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1308\n","  reward       |  1.45\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1354\n","  reward       |  1.4\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1388\n","  reward       |  1.255\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1421\n","  reward       |  0.925\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1462\n","  reward       |  1.435\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1490\n","  reward       |  1.17\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1528\n","  reward       |  1.17\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1555\n","  reward       |  1.435\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1595\n","  reward       |  1.33\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1629\n","  reward       |  1.88\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1666\n","  reward       |  0.445\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1697\n","  reward       |  1.29\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1736\n","  reward       |  1.265\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1772\n","  reward       |  1.51\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1803\n","  reward       |  1.18\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1839\n","  reward       |  0.93\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1871\n","  reward       |  0.86\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1917\n","  reward       |  0.665\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1961\n","  reward       |  1.12\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1997\n","  reward       |  1.205\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2035\n","  reward       |  1.015\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2065\n","  reward       |  1.135\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2100\n","  reward       |  1.175\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2128\n","  reward       |  0.725\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2160\n","  reward       |  1.445\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2201\n","  reward       |  1.505\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2232\n","  reward       |  0.86\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2257\n","  reward       |  0.565\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2294\n","  reward       |  1.95\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2327\n","  reward       |  0.925\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2362\n","  reward       |  1.3\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2400\n","  reward       |  1.25\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2424\n","  reward       |  1.065\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2460\n","  reward       |  1.51\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2493\n","  reward       |  1.15\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2531\n","  reward       |  1.1\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2570\n","  reward       |  1.175\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2602\n","  reward       |  1.1\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2640\n","  reward       |  1.27\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2675\n","  reward       |  1.01\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2709\n","  reward       |  0.91\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2738\n","  reward       |  1.16\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2764\n","  reward       |  1.045\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2797\n","  reward       |  1.4\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2837\n","  reward       |  1.145\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2878\n","  reward       |  0.485\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2914\n","  reward       |  1.2\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2945\n","  reward       |  1.03\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2976\n","  reward       |  0.9\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3004\n","  reward       |  1.765\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3035\n","  reward       |  0.87\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3069\n","  reward       |  1.545\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3099\n","  reward       |  1.06\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3132\n","  reward       |  1.215\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3166\n","  reward       |  1.765\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3196\n","  reward       |  1.325\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3228\n","  reward       |  0.76\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3261\n","  reward       |  0.69\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3292\n","  reward       |  1.07\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3338\n","  reward       |  1.36\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  3372\n","  reward       |  1.55\n","----------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"UcTuXaqCnq5B","executionInfo":{"status":"ok","timestamp":1606161392966,"user_tz":-60,"elapsed":27582,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"c494032b-7e3c-4e46-db0e-f2ae816d3359"},"source":["# Plot the learning curve\n","title = 'Leduc Holdem DQN action version: ' + str(extra_action_version) + ', agent training: ' + str(opponent_agent_version_train) + ', agent eval: ' + str(opponent_agent_version_eval)\n","plot(log_dir, title)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["./experiments/leduc_holdem_dqn_result/performance.csv\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"-LgUO6Wh20AV","executionInfo":{"status":"ok","timestamp":1606161754121,"user_tz":-60,"elapsed":942,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["from rlcard.agents import LeducholdemHumanAgent as HumanAgent\n","from rlcard.utils import print_card\n","\n","def play_game(num):\n","  ''' \n","  Playing game with the pre-trained agent\n","\n","  :param int num: Number of rounds\n","  '''\n","  # Make environment\n","  # Set 'record_action' to True because we need it to print results\n","  env = rlcard.make('leduc-holdem', config={'record_action': True})\n","  # Create human agent\n","  human_agent = HumanAgent(env.action_num)\n","  env.set_agents([human_agent, agent])\n","\n","  print(\">> Leduc Hold'em pre-trained model\")\n","  i=0\n","  while (i<num):\n","      print(\">> Start a new game\")\n","\n","      trajectories, payoffs = env.run(is_training=False)\n","      # If the human does not take the final action, we need to\n","      # print other players action\n","      final_state = trajectories[0][-1][-2]\n","      action_record = final_state['action_record']\n","      state = final_state['raw_obs']\n","      _action_list = []\n","      for i in range(1, len(action_record)+1):\n","          if action_record[-i][0] == state['current_player']:\n","              break\n","          _action_list.insert(0, action_record[-i])\n","      for pair in _action_list:\n","          print('>> Player', pair[0], 'chooses', pair[1])\n","\n","      # Display the card of the agent\n","      print('===============     DQN Agent    ===============')\n","      print_card(env.get_perfect_information()['hand_cards'][1])\n","\n","      # Display the result (number of chips)\n","      print('===============     Result     ===============')\n","      if payoffs[0] > 0:\n","          print('You win {} chips!'.format(payoffs[0]))\n","      elif payoffs[0] == 0:\n","          print('It is a tie.')\n","      else:\n","          print('You lose {} chips!'.format(-payoffs[0]))\n","      print('')\n","      i += 1\n","      input(\"Press any key to continue...\")\n","  input(\">> End of the game\")"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eEboxRSKo-nt","executionInfo":{"status":"ok","timestamp":1606161786567,"user_tz":-60,"elapsed":28125,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"c666ca40-be10-4fa5-aab3-8a07089a9beb"},"source":["# Playing game with the pre-trained agent\n","play_game(1)"],"execution_count":15,"outputs":[{"output_type":"stream","text":[">> Leduc Hold'em pre-trained model\n",">> Start a new game\n","\n","=============== Community Card ===============\n","┌─────────┐\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","└─────────┘\n","===============   Your Hand    ===============\n","┌─────────┐\n","│K        │\n","│         │\n","│         │\n","│    ♥    │\n","│         │\n","│         │\n","│        K│\n","└─────────┘\n","===============     Chips      ===============\n","Yours:   +\n","Agent 1: ++\n","=========== Actions You Can Choose ===========\n","0: call, 1: raise, 2: fold\n","\n",">> You choose action (integer): 1\n",">> Player 1 chooses raise\n","\n","=============== Community Card ===============\n","┌─────────┐\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","│░░░░░░░░░│\n","└─────────┘\n","===============   Your Hand    ===============\n","┌─────────┐\n","│K        │\n","│         │\n","│         │\n","│    ♥    │\n","│         │\n","│         │\n","│        K│\n","└─────────┘\n","===============     Chips      ===============\n","Yours:   ++++\n","Agent 1: ++++++\n","=========== Actions You Can Choose ===========\n","0: call, 1: fold\n","\n",">> You choose action (integer): 0\n",">> Player 1 chooses raise\n","\n","=============== Community Card ===============\n","┌─────────┐\n","│Q        │\n","│         │\n","│         │\n","│    ♥    │\n","│         │\n","│         │\n","│        Q│\n","└─────────┘\n","===============   Your Hand    ===============\n","┌─────────┐\n","│K        │\n","│         │\n","│         │\n","│    ♥    │\n","│         │\n","│         │\n","│        K│\n","└─────────┘\n","===============     Chips      ===============\n","Yours:   ++++++\n","Agent 1: ++++++++++\n","=========== Actions You Can Choose ===========\n","0: call, 1: raise, 2: fold\n","\n",">> You choose action (integer): 0\n",">> Player 0 chooses call\n","===============     DQN Agent    ===============\n","┌─────────┐\n","│J        │\n","│         │\n","│         │\n","│    ♥    │\n","│         │\n","│         │\n","│        J│\n","└─────────┘\n","===============     Result     ===============\n","You win 5.0 chips!\n","\n","Press any key to continue...\n",">> End of the game\n"],"name":"stdout"}]}]}