{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"poker-bot-dqn-limit-notebook.ipynb","provenance":[{"file_id":"1JWeHYPGubMrUHnNnvgtyFwvPz-ZYlW_l","timestamp":1605439097828}],"collapsed_sections":[],"authorship_tag":"ABX9TyMrZ/3Xz4zPMmkGFTonGlvc"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"aRJsfnUrmS_H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606045762029,"user_tz":-60,"elapsed":10225,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"bcefe5d6-fa5a-4d9c-dc62-5ee69387caee"},"source":["!pip install git+https://github.com/datamllab/rlcard"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/datamllab/rlcard\n","  Cloning https://github.com/datamllab/rlcard to /tmp/pip-req-build-2kr6m75z\n","  Running command git clone -q https://github.com/datamllab/rlcard /tmp/pip-req-build-2kr6m75z\n","Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (1.18.5)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (3.2.2)\n","Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (7.0.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (1.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from rlcard==0.2.6) (20.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->rlcard==0.2.6) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->rlcard==0.2.6) (1.15.0)\n","Building wheels for collected packages: rlcard\n","  Building wheel for rlcard (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rlcard: filename=rlcard-0.2.6-cp36-none-any.whl size=6785384 sha256=b50d4c7711ca87c75782f3557be16022875e0bfc13391bd5b271d03d7309b15e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-r18hxz6n/wheels/b3/e1/32/6535ad7ff9142e4c031af97e237e4df3e4ab14e86194738ac4\n","Successfully built rlcard\n","Installing collected packages: rlcard\n","Successfully installed rlcard-0.2.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V9-pPwFQmjxb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606045767213,"user_tz":-60,"elapsed":15384,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"ffa28a0e-c065-48da-96c2-67a28a1f45c8"},"source":["%tensorflow_version 1.x # for using tensorflow.contrib\n","import tensorflow as tf"],"execution_count":2,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.x # for using tensorflow.contrib`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_DjHYr9NmBE8","executionInfo":{"status":"ok","timestamp":1606045767216,"user_tz":-60,"elapsed":15383,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["from collections import namedtuple\n","import random\n","import numpy as np\n","\n","Transition = namedtuple('Transition', ['state', 'action', 'reward', 'next_state', 'done'])\n","\n","class ReplayMemory(object):\n","    ''' \n","    Replay memory for saving transitions\n","    '''\n","    def __init__(self, capacity, batch_size):\n","        ''' \n","        Initialize ReplayMemory\n","\n","        :param int capacity: the size of the memory buffer\n","        :param int batch_size: the size of the batches\n","        '''\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    def push(self, *args):\n","        '''\n","        Save a transition into memory\n","        '''\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        '''\n","        Choose random sample from the memory with size of the batch size\n","        '''\n","        samples = random.sample(self.memory, batch_size)\n","        return map(np.array, zip(*samples))\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJOP-_FYlz_X","executionInfo":{"status":"ok","timestamp":1606045769835,"user_tz":-60,"elapsed":17997,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","class DQN_network(object):\n","    '''\n","    Deep Q-Network\n","    '''\n","\n","    def __init__(self, state_no=36, act_no=4, hidden_layers=[64, 32], learning_rate=0.001, device=None):\n","        ''' \n","        Initilalize the DQN_network object.\n","\n","        :param act_no (int): Number of actions (4 in Leduc Hold'em)\n","        :param state_no (list): Size of the state space (36 in Leduc Hold'em)\n","        :param hidden_layers (list): Dimension of the hidden layers\n","        :param device (torch.device): Usage CPU or GPU\n","        '''\n","        self.state_no = state_no\n","        self.act_no = act_no\n","        self.hidden_layers = hidden_layers\n","        self.learning_rate=learning_rate\n","        self.device = device\n","\n","        # DQN network based on the layers\n","        layers = self.state_no + self.hidden_layers\n","        DQN_network = [nn.Flatten()]\n","        DQN_network.append(nn.BatchNorm1d(layers[0]))\n","        for i in range(len(layers)-1):\n","            DQN_network.append(nn.Linear(layers[i], layers[i+1], bias=True))\n","            DQN_network.append(nn.Tanh())\n","        DQN_network.append(nn.Linear(layers[-1], self.act_no, bias=True))\n","        DQN_network = nn.Sequential(*DQN_network)\n","\n","        DQN_network = DQN_network.to(self.device)\n","        self.DQN_network = DQN_network\n","        self.DQN_network.eval()\n","\n","        # Initialize weights in the network\n","        for p in self.DQN_network.parameters():\n","            if len(p.data.shape) > 1:\n","                nn.init.xavier_uniform_(p.data)\n","\n","        # Define loss function\n","        self.loss_function = nn.MSELoss(reduction='mean')\n","\n","        # Define optimizer\n","        #self.optimizer =  torch.optim.Adam(self.DQN_network.parameters(), lr=self.learning_rate)\n","        self.optimizer = torch.optim.RMSprop(self.DQN_network.parameters())\n","\n","\n","    def get_qvalue(self, next_state_batch):\n","        ''' \n","        Get Q-values for the batch of the next states.\n","        It does not use gradient calculation.\n","\n","        :param np.ndarray next_state_batch: Batch of the next states\n","        :return np.ndarray Q_values: The estimated Q-values\n","        '''\n","        # Disable gradient calculation\n","        with torch.no_grad():\n","            # Create torch tensor\n","            next_state_batch = torch.from_numpy(next_state_batch).float().to(self.device)\n","            # Get Q values\n","            Q_values = self.DQN_network(next_state_batch).cpu().numpy()\n","        return Q_values\n","\n","    def update(self, state_batch, action_batch, target_batch):\n","        ''' \n","        Update the policy network\n","\n","        :param np.ndarray state_batch: Batch of states from replay memory\n","        :param np.ndarray action_batch: Batch of actions from replay memory\n","        :param np.ndarray target_batch: Batch of Q-values from the target policy, it used during the optimization step\n","        :return float batch_loss: The calculated loss on the batch       \n","        '''\n","        # Set the gradients to zero\n","        self.optimizer.zero_grad()\n","\n","        # Set the network in training mode\n","        self.DQN_network.train()\n","\n","        # Create torch tensors\n","        state_batch = torch.from_numpy(state_batch).float().to(self.device)\n","        action_batch = torch.from_numpy(action_batch).long().to(self.device)\n","        target_batch = torch.from_numpy(target_batch).float().to(self.device)\n","\n","        # Gather Q-values from network and replay memory actions\n","        Q_values = torch.gather(self.DQN_network(state_batch), dim=-1, index=action_batch.unsqueeze(-1)).squeeze(-1)\n","\n","        # Optimization step\n","        batch_loss = self.loss_function(Q_values, target_batch)\n","        batch_loss.backward()\n","        self.optimizer.step()\n","        batch_loss = batch_loss.item()\n","        self.DQN_network.eval()\n","        return batch_loss\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCR4YvyTl8Ga","executionInfo":{"status":"ok","timestamp":1606045769839,"user_tz":-60,"elapsed":17994,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from copy import deepcopy\n","import random\n","\n","class DQN_agent(object):\n","    '''\n","    DQN agent\n","    '''\n","    def __init__(self,\n","                state_no,\n","                act_no,\n","                extra_action_version=0,\n","                replay_memory_capacity=20000,\n","                replay_memory_min_sample=1000,\n","                batch_size=32,\n","                training_period=1,\n","                discount_factor=0.99,\n","                hidden_layers=[64, 32],\n","                learning_rate=0.0001,\n","                epsilon_decay_steps=20000,\n","                update_target_dqn_period=1000, \n","                device=None):\n","\n","        '''\n","        Initialize the DQN agent\n","\n","        :param int state_no: Number of states\n","        :param int act_no: Number of actions\n","        :param int extra_action_version: Mode of choosing action during evaluation phase. Action with maximum value: 0, Raise action instead of Call if possible: 1, Raise action instead of Check if possible: 2, Raise action instead of Fold if possible: 3\n","        :param int replay_memory_capacity: Replay memory size\n","        :param int replay_memory_min_sample: Minimum number of samples in the replay memory during sampling\n","        :param int batch_size: Size of batches to sample from the replay memory\n","        :param int training_period: Train the network in every N steps\n","        :param float discount_factor: Discount factor (gamma) during training the agent\n","        :param list[int] hidden_layers: Dimensions of the hidden layers in the DQN network\n","        :param float learning_rate: The learning rate in the DQN network\n","        :param int epsilon_decay_steps: Number of steps to decay epsilon\n","        :param int update_target_dqn_period: Update target network in every N steps\n","        :param torch.device device: Usage CPU or GPU\n","        '''\n","        \n","        self.replay_memory_min_sample = replay_memory_min_sample\n","        self.update_target_dqn_period = update_target_dqn_period\n","        self.discount_factor = discount_factor\n","        self.epsilon_decay_steps = epsilon_decay_steps\n","        self.batch_size = batch_size\n","        self.act_no = act_no\n","        self.training_period = training_period\n","        self.extra_action_version = extra_action_version\n","\n","        # Torch device on which a torch.Tensor will be allocated\n","        if device is None:\n","            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        else:\n","            self.device = device\n","\n","        # Create the replay memory\n","        self.memory = ReplayMemory(replay_memory_capacity, batch_size)\n","\n","        # Initialize current timestep and current training timestep\n","        self.current_timestep, self.current_training_timestep = 0, 0\n","\n","        # Create array for the epsilon values during the epsilon decay \n","        self.epsilons = np.linspace(1.0, 0.1, epsilon_decay_steps)\n","\n","        # Create the policy and the target network\n","        self.policy_dqn = DQN_network(act_no=act_no, learning_rate=learning_rate, state_no=state_no, hidden_layers=hidden_layers, device=self.device)\n","        self.target_dqn = DQN_network(act_no=act_no, learning_rate=learning_rate, state_no=state_no, hidden_layers=hidden_layers, device=self.device)\n","\n","        # Set use_raw value for the RLCard environment\n","        self.use_raw = False\n","\n","    def store_and_train(self, transition):\n","        ''' \n","        Save transition into memory and train the agent based on the training period.\n","\n","        :param tuple transition: The transition tuple 'state', 'action', 'reward', 'next_state', 'done'\n","        \n","        '''\n","        (state, action, reward, next_state, done) = tuple(transition)\n","\n","        # Store transition in replay memory\n","        self.memory.push(state['obs'], action, reward, next_state['obs'], done)\n","        # Increment the number of timesteps\n","        self.current_timestep += 1\n","        # Train the agent if the replay memory has data already and agent reached the next training period\n","        time_between = self.current_timestep - self.replay_memory_min_sample\n","        if time_between>=0 and time_between%self.training_period == 0:\n","            self.train()\n","\n","    def discard_invalid_actions(self, action_probs, valid_actions):\n","        ''' \n","        Remove invalid actions and normalize the probabilities.\n","\n","        :param numpy.array[float] action_probs: Probabilities of all action\n","        :param list[int] valid_actions: Valid actions in the current state\n","        :return numpy.array[float] norm_valid_action_probs: Probabilities of valid actions\n","        '''\n","        # Initialize new array\n","        norm_valid_action_probs = np.zeros(action_probs.shape[0])\n","        # Add probability values of valid actions to the array\n","        norm_valid_action_probs[valid_actions] = action_probs[valid_actions]\n","        # Normalize probabilities\n","        norm_valid_action_probs[valid_actions] = 1 / len(valid_actions)\n","        return norm_valid_action_probs\n","\n","    def predict(self, state):\n","        ''' \n","        Predict the action probabilities.\n","\n","        :param numpy.array[float] state: Current state\n","        :return numpy.array[float] q_values: Array of Q values  \n","        '''\n","        epsilon = self.epsilons[min(self.current_timestep, self.epsilon_decay_steps-1)]\n","        actions = np.ones(self.act_no, dtype=float) * epsilon / self.act_no\n","        q_values = self.policy_dqn.get_qvalue(np.expand_dims(state, 0))[0]\n","        best_action = np.argmax(q_values)\n","        actions[best_action] += (1.0 - epsilon)\n","        return actions\n","\n","    def step(self, state):\n","        ''' \n","        Define step function for the RLCard environment.\n","        Get the action for the current state for training purpose.\n","        If neccessary, remove invalid action pobabilities.\n","\n","        :param numpy.array state: The current state\n","        :return int action: The chosen action in the current state\n","        '''\n","        actions = self.predict(state['obs'])\n","        norm_valid_action_probs = self.discard_invalid_actions(actions, state['legal_actions'])\n","        action = np.random.choice(np.arange(len(actions)), p=norm_valid_action_probs)\n","        return action\n","\n","\n","    def eval_step(self, state):\n","        ''' \n","        Define eval_step function for the RLCard environment.\n","        Get the action for the evaluation purpose instead of training purpose.\n","\n","        :param numpy.array state: The current state\n","        :return int action: The chosen action in the current state\n","        '''\n","        q_values = self.policy_dqn.get_qvalue(np.expand_dims(state['obs'], 0))[0]\n","        norm_valid_action_probs = self.discard_invalid_actions(np.exp(q_values), state['legal_actions'])\n","        # Check version of choosing action\n","        if self.extra_action_version == 1:\n","          # If Raise (1) is a valid action and the best action is Call (0)\n","          if 1 in state['legal_actions'] and np.argmax(norm_valid_action_probs)==0:\n","            best_action = 1\n","          else:\n","            best_action = np.argmax(norm_valid_action_probs)\n","        elif self.extra_action_version == 2:\n","          # If Raise (1) is a valid action and the best action is Check (3)\n","          if 1 in state['legal_actions'] and np.argmax(norm_valid_action_probs)==3:\n","            best_action = 1\n","          else:\n","            best_action = np.argmax(norm_valid_action_probs)\n","        elif self.extra_action_version == 3:\n","          # If Raise (1) is a valid action and the best action is Fold (2)\n","          if 1 in state['legal_actions'] and np.argmax(norm_valid_action_probs)==2:\n","            best_action = 1\n","          else:\n","            best_action = np.argmax(norm_valid_action_probs)\n","        else:\n","          best_action = np.argmax(norm_valid_action_probs)\n","        return best_action, norm_valid_action_probs\n","\n","    \n","    def train(self):\n","        ''' \n","        Train the agent.\n","\n","        return float loss: The loss of the current batch\n","        '''\n","        state_batch, action_batch, reward_batch, next_state_batch, done_batch = self.memory.sample(self.batch_size)\n","\n","        # Get best next action using the policy network\n","        q_values_next = self.policy_dqn.get_qvalue(next_state_batch)\n","        best_actions = np.argmax(q_values_next, axis=1)\n","\n","        # Calculate Q values from the target policy\n","        q_values_next_target = self.target_dqn.get_qvalue(next_state_batch)\n","        target_batch = reward_batch + np.invert(done_batch).astype(np.float32) * self.discount_factor * q_values_next_target[np.arange(self.batch_size), best_actions]\n","\n","        # Update policy network\n","        state_batch = np.array(state_batch)\n","        loss = self.policy_dqn.update(state_batch, action_batch, target_batch)\n","\n","        # Update target network based on the target update period\n","        if self.current_training_timestep % self.update_target_dqn_period == 0:\n","            self.target_dqn = deepcopy(self.policy_dqn)\n","\n","        self.current_training_timestep += 1\n","\n","\n","    def get_state_dict(self):\n","        ''' \n","        Get the state dictionaries.\n","\n","        :return dict model_dict: Dictionaries containing the whole state of the policy and target modules\n","        '''\n","        model_dict = {'policy_network': self.policy_dqn.DQN_network.state_dict(), 'target_network': self.target_dqn.DQN_network.state_dict()}\n","        return model_dict\n","\n","    def load_networks(self, checkpoint):\n","        ''' \n","        Load network models.\n","\n","        :param dict checkpoint: Checkpoint of the policy and target networks\n","        '''\n","        self.policy_dqn.DQN_network.load_state_dict(checkpoint['policy_network'])\n","        self.target_dqn.DQN_network.load_state_dict(checkpoint['target_network'])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-6cxXx8yYcW","executionInfo":{"status":"ok","timestamp":1606045776897,"user_tz":-60,"elapsed":953,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}}},"source":["import os\n","import csv\n","import matplotlib.pyplot as plt\n","\n","def plot(logdir, title):\n","    ''' \n","    Read data from csv file and plot the results\n","\n","    :param string logdir: Logging directory\n","    :param string title: Title of the plot\n","    '''\n","    csv_path = os.path.join(log_dir, 'performance.csv')\n","    save_path = log_dir\n","\n","    with open(csv_path) as csvfile:\n","        print(csv_path)\n","        reader = csv.DictReader(csvfile)\n","        xs = [0]\n","        ys = [0]\n","        for row in reader:\n","            xs.append(int(row['timestep']))\n","            ys.append(float(row['reward']))\n","        plt.plot(xs, ys)\n","        plt.xlabel('timestep')\n","        plt.ylabel('reward')\n","        plt.title(title)\n","        plt.legend(['DQN'])\n","        plt.ylim(min(-0.5, min(ys)), max(ys)+0.5)\n","        plt.grid()\n","        plt.savefig(save_path)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZK0dotrUla77","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606045798539,"user_tz":-60,"elapsed":14455,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"34e3db43-7111-49cf-fbe9-b82ddffc521b"},"source":["import rlcard\n","from rlcard import models\n","from rlcard.agents import RandomAgent\n","from rlcard.utils import seeding, tournament\n","from rlcard.utils import Logger\n","import torch\n","import os\n","\n","# Create environments\n","env = rlcard.make('limit-holdem', config={'seed': 0})\n","eval_env = rlcard.make('limit-holdem', config={'seed': 0})\n","\n","# Set a global seed\n","seeding.create_seed(0)\n","\n","# Play agressive game based on the version of choosing actual action\n","# Action with maximum value: 0\n","# Raise action instead of Call if possible: 1\n","# Raise action instead of Check if possible: 2\n","# Raise action instead of Fold if possible: 3\n","extra_action_version=1\n","\n","# The paths for saving the logs and learning curves\n","log_dir = './experiments/limit_holdem_dqn_result/'\n","\n","# Create DQN agent\n","agent = DQN_agent(state_no=env.state_shape,\n","                  act_no=env.action_num, \n","                  replay_memory_min_sample=1000,\n","                  training_period=10,\n","                  hidden_layers=[128, 128],\n","                  device=torch.device('cpu'),\n","                  extra_action_version=extra_action_version)\n","\n","# Create random opponent agent\n","random_agent = RandomAgent(action_num=eval_env.action_num)\n","\n","# Add the agent to the environments\n","env.set_agents([agent, random_agent])\n","eval_env.set_agents([agent, random_agent])\n","\n","# Initialize logger\n","logger = Logger(log_dir)\n","\n","# Number of episodes, number of games during evaluation and evaluation in every N steps\n","episode_no, evaluate_games, evaluate_period = 1000, 100, 10\n","\n","for episode in range(episode_no):\n","    # Generate data from the environment\n","    trajectories, _ = env.run(is_training=True)\n","\n","    # Feed transitions into agent memory, and train the agent\n","    for ts in trajectories[0]:\n","        agent.store_and_train(ts)\n","\n","    # Evaluate the performance\n","    if episode % evaluate_period == 0:\n","        logger.log_performance(env.timestep, tournament(eval_env, evaluate_games)[0])\n","\n","# Close files in the logger\n","logger.close_files()\n","\n","# Save model\n","save_dir = 'models/dqn'\n","if not os.path.exists(save_dir):\n","    os.makedirs(save_dir)\n","state_dict = agent.get_state_dict()\n","torch.save(state_dict, os.path.join(save_dir, 'model.pth'))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["\n","----------------------------------------\n","  timestep     |  1\n","  reward       |  3.76\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  35\n","  reward       |  3.27\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  78\n","  reward       |  2.83\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  104\n","  reward       |  3.215\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  134\n","  reward       |  2.965\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  174\n","  reward       |  4.315\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  199\n","  reward       |  3.12\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  221\n","  reward       |  2.065\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  257\n","  reward       |  3.605\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  278\n","  reward       |  2.865\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  306\n","  reward       |  2.805\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  323\n","  reward       |  3.3\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  354\n","  reward       |  2.655\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  376\n","  reward       |  1.71\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  405\n","  reward       |  3.505\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  438\n","  reward       |  2.4\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  473\n","  reward       |  2.26\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  508\n","  reward       |  2.835\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  547\n","  reward       |  2.455\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  577\n","  reward       |  3.25\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  607\n","  reward       |  3.66\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  625\n","  reward       |  3.065\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  656\n","  reward       |  2.8\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  680\n","  reward       |  2.65\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  716\n","  reward       |  2.325\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  743\n","  reward       |  3.31\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  765\n","  reward       |  2.52\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  805\n","  reward       |  3.245\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  838\n","  reward       |  3.085\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  874\n","  reward       |  3.61\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  894\n","  reward       |  2.775\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  940\n","  reward       |  2.22\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  959\n","  reward       |  3.005\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  988\n","  reward       |  2.005\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1018\n","  reward       |  2.595\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1053\n","  reward       |  2.87\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1072\n","  reward       |  3.14\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1094\n","  reward       |  2.37\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1123\n","  reward       |  3.77\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1150\n","  reward       |  2.78\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1176\n","  reward       |  3.75\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1210\n","  reward       |  2.29\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1244\n","  reward       |  2.655\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1273\n","  reward       |  2.365\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1305\n","  reward       |  2.965\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1339\n","  reward       |  3.24\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1375\n","  reward       |  2.735\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1404\n","  reward       |  2.205\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1430\n","  reward       |  2.655\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1474\n","  reward       |  2.785\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1499\n","  reward       |  3.675\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1533\n","  reward       |  3.15\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1554\n","  reward       |  2.995\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1582\n","  reward       |  2.73\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1605\n","  reward       |  2.98\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1629\n","  reward       |  2.905\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1655\n","  reward       |  2.225\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1681\n","  reward       |  2.09\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1703\n","  reward       |  2.81\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1728\n","  reward       |  3.075\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1753\n","  reward       |  2.695\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1806\n","  reward       |  1.585\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1846\n","  reward       |  3.09\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1878\n","  reward       |  3.085\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1912\n","  reward       |  2.95\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1953\n","  reward       |  2.795\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  1984\n","  reward       |  3.19\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2027\n","  reward       |  2.675\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2042\n","  reward       |  2.91\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2064\n","  reward       |  3.325\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2086\n","  reward       |  2.855\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2115\n","  reward       |  2.235\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2147\n","  reward       |  2.69\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2181\n","  reward       |  3.15\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2217\n","  reward       |  2.1\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2250\n","  reward       |  2.635\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2277\n","  reward       |  3.59\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2305\n","  reward       |  2.68\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2329\n","  reward       |  3.62\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2369\n","  reward       |  2.37\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2398\n","  reward       |  2.595\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2436\n","  reward       |  2.18\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2454\n","  reward       |  2.66\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2485\n","  reward       |  2.01\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2522\n","  reward       |  3.045\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2549\n","  reward       |  3.02\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2570\n","  reward       |  2.455\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2605\n","  reward       |  2.025\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2633\n","  reward       |  2.42\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2660\n","  reward       |  2.755\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2690\n","  reward       |  2.9\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2713\n","  reward       |  3.285\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2740\n","  reward       |  3.05\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2766\n","  reward       |  2.9\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2794\n","  reward       |  2.535\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2822\n","  reward       |  2.87\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2865\n","  reward       |  3.59\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2881\n","  reward       |  2.255\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2902\n","  reward       |  2.705\n","----------------------------------------\n","\n","----------------------------------------\n","  timestep     |  2926\n","  reward       |  3.48\n","----------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UcTuXaqCnq5B","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"ok","timestamp":1606045830126,"user_tz":-60,"elapsed":1040,"user":{"displayName":"Mónika Farsang","photoUrl":"","userId":"03651393462520036310"}},"outputId":"c2e5145a-4584-414d-a8a9-cfa297e870d2"},"source":["# Plot the learning curve\n","title = 'Limit Holdem DQN action version: ' + str(extra_action_version)\n","plot(log_dir, title)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["./experiments/limit_holdem_dqn_result/performance.csv\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}